{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T15:47:12.449543Z",
     "start_time": "2019-12-31T15:47:08.605225Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import sleep, time\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib.request\n",
    "import datetime\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T15:47:12.454289Z",
     "start_time": "2019-12-31T15:47:12.450872Z"
    }
   },
   "outputs": [],
   "source": [
    "namepackages = []\n",
    "\n",
    "def get_url_packages(url):\n",
    "    print(\"Scraping: \", url)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    table = soup.find( \"table\" )\n",
    "\n",
    "    for row in table.findAll(\"a\"):\n",
    "\n",
    "        name = row.text\n",
    "        url = row.get('href').replace(\"../../\", \"https://cran.r-project.org/\")\n",
    "\n",
    "        namepackages.append({\"name\": name, \"url\": url})\n",
    "    return namepackages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T15:47:14.695459Z",
     "start_time": "2019-12-31T15:47:12.455434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping:  https://cran.r-project.org/web/packages/available_packages_by_name.html\n",
      "Elapsed run time: 2.045599937438965 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "\n",
    "url = ['https://cran.r-project.org/web/packages/available_packages_by_name.html']\n",
    "\n",
    "with Pool(cpu_count()-1) as p:\n",
    "    urls_packages = p.map(get_url_packages, url)\n",
    "p.close()\n",
    "p.join()\n",
    "end_time = time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f'Elapsed run time: {elapsed_time} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T15:47:16.558020Z",
     "start_time": "2019-12-31T15:47:16.464981Z"
    }
   },
   "outputs": [],
   "source": [
    "for pkg in urls_packages:\n",
    "    df = pd.DataFrame.from_dict(pkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T15:47:16.954383Z",
     "start_time": "2019-12-31T15:47:16.653109Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3</td>\n",
       "      <td>https://cran.r-project.org/web/packages/A3/ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaSEA</td>\n",
       "      <td>https://cran.r-project.org/web/packages/aaSEA/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABACUS</td>\n",
       "      <td>https://cran.r-project.org/web/packages/ABACUS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abbyyR</td>\n",
       "      <td>https://cran.r-project.org/web/packages/abbyyR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abc</td>\n",
       "      <td>https://cran.r-project.org/web/packages/abc/in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name                                                url\n",
       "0      A3  https://cran.r-project.org/web/packages/A3/ind...\n",
       "1   aaSEA  https://cran.r-project.org/web/packages/aaSEA/...\n",
       "2  ABACUS  https://cran.r-project.org/web/packages/ABACUS...\n",
       "3  abbyyR  https://cran.r-project.org/web/packages/abbyyR...\n",
       "4     abc  https://cran.r-project.org/web/packages/abc/in..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T15:47:18.617566Z",
     "start_time": "2019-12-31T15:47:18.614387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15368"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listPackages = df[\"url\"].tolist()\n",
    "len(listPackages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T15:47:20.337809Z",
     "start_time": "2019-12-31T15:47:20.335428Z"
    }
   },
   "outputs": [],
   "source": [
    "def replace_all(text, dic):\n",
    "    for i, j in dic.items():\n",
    "        text = text.replace(i, j)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T15:47:21.408142Z",
     "start_time": "2019-12-31T15:47:20.949898Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "mongo = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "database = mongo[\"PY_CRAN\"]\n",
    "collection = database[\"R_packages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T15:47:23.961803Z",
     "start_time": "2019-12-31T15:47:23.468883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed run time: 2.3126602172851562e-05 seconds\n"
     ]
    }
   ],
   "source": [
    "import asyncio, re\n",
    "from aiohttp import ClientSession\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "chr_replace = { \":\": \"\", \"\\n\": \"\", \" \": \"\", \"\\t\": \"\"}\n",
    "MAX_SIM_CONNS = 50\n",
    "\n",
    "async def fetch(url, session):\n",
    "    async with session.get(url) as response:\n",
    "         text = await response.read()\n",
    "            \n",
    "    data = {}\n",
    "    soup = BeautifulSoup(text, \"lxml\")\n",
    "        \n",
    "    title = soup.find(\"h2\").text\n",
    "    description = soup.select(\"body > p\")[0].text\n",
    "    title_s = title.split(\":\")\n",
    "    \n",
    "    data['Package'] = replace_all(title_s[0].strip(), chr_replace)\n",
    "    data['Title'] = replace_all(title_s[1].strip(), chr_replace)\n",
    "    data['Description'] = replace_all(description.strip(), chr_replace)\n",
    "    \n",
    "    for table in soup.findAll('table'):\n",
    "        rows = table.findAll(\"tr\")\n",
    "        for i in range(len(rows)):\n",
    "            td_list = rows[i].findAll('td')\n",
    "\n",
    "            name = \"_\".join(replace_all(td_list[0].text.strip(), chr_replace).split())\n",
    "            value = replace_all(td_list[1].text.strip(), chr_replace).strip()\n",
    "            \n",
    "            #(?!<(?:\\<|\\[|\\(|\\\")[^\"\\)\\]\\>]+),(?![^.\\\"\\(\\[\\<]+(?:\\.|\\\"|\\>|\\)|\\]|\\>)) #Primera Prueba\n",
    "            #(?!<(?:\\<|\\\"|\\[|\\()[^)\\]\\\"\\>]+),(?![^(\\[\\\"\\<]+(?:\\>|\\\"|\\)|\\]|\\>)) # Segunda Prueba\n",
    "            #(?!<(?:\\<|\\\"|\\[|\\()[^)\\]\\\"\\>]+)[,|;](?![^(\\[\\\"\\<]+(?:\\>|\\\"|\\)|\\]|\\>)) # Tercera Prueba\n",
    "            #(?!<(?:\\<|\\\"|\\[|\\()[^)\\]\\\"\\>]+)[,|;](?![^(\\[\\\"\\<]+(?:\\>|\\)|\\]|\\>))\n",
    "            \n",
    "\n",
    "            if (re.findall(r'(,|;)', value)):\n",
    "                \n",
    "                if ( (name == 'Author') | (name == 'Maintainer') ):\n",
    "                    \n",
    "                    value_T = re.sub(r'\\(.*?\\)\\)\\)', '', value) # Remueve caracteres dentro de parentesis\n",
    "                    value_T0 = re.sub(r'\\(.*?\\)\\)', '', value_T)\n",
    "                    value_T1 = re.sub(r'\\([^()]*\\)', '', value_T0)\n",
    "                    value_T2 = re.sub(r'\\(.*?\\)', '', value_T1)\n",
    "            \n",
    "                    value_s = re.split('(?!<(?:\\<|\\\"|\\[|\\()[^)\\]\\\"\\>]+)[,|;](?![^(\\[\\\"\\<]+(?:\\>|\\)|\\]|\\>))', value_T2)\n",
    "                else:\n",
    "                    value_s = re.split('(?!<(?:\\<|\\\"|\\[|\\()[^)\\]\\\"\\>]+)[,|;](?![^(\\[\\\"\\<]+(?:\\>|\\)|\\]|\\>))', value)\n",
    "                \n",
    "                #print(name, value_s)\n",
    "                data[name] = value_s\n",
    "            else:\n",
    "                #print(name, value_T2) \n",
    "                if ( (name == 'Author') | (name == 'Maintainer') ):\n",
    "                    value_T = re.sub(r'\\(.*?\\)\\)\\)', '', value) # Remueve caracteres dentro de parentesis\n",
    "                    value_T0 = re.sub(r'\\(.*?\\)\\)', '', value_T)\n",
    "                    value_T1 = re.sub(r'\\([^()]*\\)', '', value_T0)\n",
    "                    value_T2 = re.sub(r'\\(.*?\\)', '', value_T1)\n",
    "                    \n",
    "                    value_s = re.split('(?!<(?:\\<|\\\"|\\[|\\()[^)\\]\\\"\\>]+)[,|;](?![^(\\[\\\"\\<]+(?:\\>|\\)|\\]|\\>))', value_T2)\n",
    "\n",
    "                else:\n",
    "                    value_s = value.strip()\n",
    "                    \n",
    "                data[name] = value_s\n",
    "\n",
    "                \n",
    "       \n",
    "    collection.insert_one(data)\n",
    "    return data\n",
    "\n",
    "async def bound_fetch(sem, url, session):\n",
    "    async with sem:\n",
    "        await fetch(url, session)\n",
    "\n",
    "async def fetch_all():\n",
    "    url = \"https://cran.r-project.org/\"\n",
    "    tasks = set()\n",
    "    async with ClientSession() as session:\n",
    "        sem = asyncio.Semaphore(MAX_SIM_CONNS)\n",
    "        #df[df['name']=='gee']['url'].tolist()\n",
    "        for url_pkg in listPackages:\n",
    "            task = asyncio.create_task(bound_fetch(sem, url_pkg, session))\n",
    "            tasks.add(task)\n",
    "        \n",
    "            #await asyncio.sleep(2)\n",
    "        return await asyncio.gather(*tasks)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time()\n",
    "    \n",
    "    loop = asyncio.get_event_loop()\n",
    "    #asyncio.run(fetch_all())\n",
    "    loop.create_task(fetch_all())\n",
    "    \n",
    "    end_time = time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "print(f'Elapsed run time: {elapsed_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
